{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb1ed0a-f108-4da5-b3c9-13f2dd1f4851",
   "metadata": {},
   "source": [
    "# Veracity Project: Distributed Ledgers and Prolog\n",
    "## Hayden McAlister - University of Otago 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d36be8-78bf-4090-a9ac-fa6a551bebc1",
   "metadata": {},
   "source": [
    "### Running this demonstration\n",
    "This demonstration is (currently) hosted on [Catalyst Cloud](https://catalystcloud.nz/). However, the IP address associated with this project is floating and could change regularly. If desired, this could be assigned some fixed domain name so this demonstration could be accessed anywhere, anytime.\n",
    "\n",
    "Otherwise, this demonstration is accessible from GitHub as a docker-compose system. [This repository](TODO) describes how to download, run, and interact with this demonstration locally. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a4185-6f9f-4a1a-b202-8dcd504545ae",
   "metadata": {},
   "source": [
    "## The infrastructure\n",
    "\n",
    "In this research project we investigated how distributed ledger technology could be used in a veracity context to verify claims and reach consensus on the state of a system. Other research was done concurrently into using Prolog to describe the state of a system and look at provenance in an organ donation scenario. I built the infrastructure to integrate this Prolog into a jupyter notebook (for accessibility and easy interaction) and expose the blockchain for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eeec1c-89f1-45e3-98b0-8833655aeb5d",
   "metadata": {},
   "source": [
    "We agreed that for a proof of concept a small scale, locally hosted blockchain would be most suitable. There is no need to put our tests on a \"real\" ledger at this stage, but if this project moves forward in this direction it may be useful to put information on a public ledger so it can be verified.\n",
    "\n",
    "My first task was to find a suitable blockchain technology that could be locally hosted. I found [Hyperledger](https://www.hyperledger.org/) to be very promising, as the opensource projects could be locally hosted and seemed very flexible to cover many situations. I looked in to using Hyperledger [Indy](https://www.hyperledger.org/use/hyperledger-indy), [Aries](https://www.hyperledger.org/use/aries), [Besu](https://www.hyperledger.org/use/besu), and [Ursa](https://www.hyperledger.org/use/ursa) but determined that [Hyperledger Iroha](https://www.hyperledger.org/use/iroha) would be most suitable for my needs. This is mainly due to Iroha having the best documentation of the projects I looked at, and was the easiest to start developing with quickly. However, other projects could absolutely be used and in future local hosting may not even be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb382ee6-8dff-4709-8dd8-562d42894e4f",
   "metadata": {},
   "source": [
    "I spent several weeks setting up infrastructure using Iroha and Docker. I managed to get four Iroha nodes running and communicating in separate containers, which is significant as four nodes is the minimum necessary to detect and correct for a single faulty node (crash fault or byzantine fault). While this demonstration does not look any further into faulty nodes, this infrastructure would support probing in this direction.\n",
    "\n",
    "We can see these containers running. If running this demonstration locally, you can run \n",
    "\n",
    "`docker container ls`\n",
    "\n",
    "and spot the containers labeled `iroha1` through `iroha4`. These containers are hosting the blockchain nodes and are constantly communicating to see if new transactions have arrived. These nodes are backed by the containers `some-postgres1` through `some-postgres4`. I am sure with enough convincing the postgres containers could be consolidated into a single container with several logins (one for each Iroha node), however this infrastructure was the easiest to develop quickly. \n",
    "\n",
    "We can also see what the current state of the blockchain is by running the following command. We will discuss this command later on, but for now just know it will query `iroha1` and get all blocks on the chain, storing them in `logs/blocks.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce9597d-b941-4138-9005-b66854c740bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "%python\n",
    "from IrohaUtils import *\n",
    "log_all_blocks(\"blocks.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b5865-2b92-47b9-bcad-f0cb220df414",
   "metadata": {},
   "source": [
    "We can see in this file that the blocks are represented in JSON format, and are mostly incomprehensible jargon. A lot of this can be understood by trawling through [the documentation](https://iroha.readthedocs.io/en/main/), however this is time consuming and very dense (I said the documentation was the best of the projects above, I did not claim the documentation was clear). For this reason, I have developed some tools we will discuss soon that make developing and interacting with the Iroha network much easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac304221-10b0-42de-bc90-7316f753f7d8",
   "metadata": {},
   "source": [
    "You may also notice other containers running due to this network. There is the `swipl-notebook` container which, unsurprisingly, runs the jupyter notebook server you are interacting with now! There is also a redis container which we will discuss later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3688ff7e-9373-4405-bc53-07c01451bc52",
   "metadata": {},
   "source": [
    "Because the goal of this project was to eventually host some Prolog work, we had to get Prolog running in a jupyter notebook. Thankfully this task was done for us (and can be found [here](https://github.com/veracitylab/jupyter-swi-prolog)), and with some scripting the jupyter notebook can run Prolog code! The kernel essentially runs Prolog line by line through a python interface with SWIPL, then dumps the factbase into a file for consultation later. These files are referenced by Prolog when querying the factbase, so the files store the state of the world. This will be useful later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56200a0-23e1-483c-b18a-fb96c4cff6d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Kernel modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2aeda6-c1d1-4233-be16-94933470d1e1",
   "metadata": {},
   "source": [
    "The kernel, while fantastic, needed extending to work with the blockchain network. I added some extra functionality which made development of Prolog with the blockchain a little easier.\n",
    "\n",
    "First, the kernel checks environment variables to determine state. This means we can easily turn on or off functionality as needed. The supported variables are:\n",
    "\n",
    "- BLOCKCHAIN: 0 or 1. Boolean check to interact with the blockchain or not. If 1 then after executing a Prolog cell the kernel will hash the fact file and store this hash on the blockchain. This provides proof that a cell was run and was added to a fact base.\n",
    "- REDIS: 0 or 1. Boolean check to interact with the redis container or not. If 1 then after execution of a Prolog cell the kernel will map the hash of the fact file with the fact file text itself. This means that if a hash is known (say, if we found it on the blockchain) then we can retrieve the file that generated it. Currently, these files are stored unencrypted\n",
    "- TIMESTAMPING: 0 or 1. Boolean check to add a timestamp to the fact files before hashing. If 0, no timestamp is added. This means that if a cell is run multiple times then only the first fact file can be stored. In particular, this means that if a cell undergoes a change from state A to B to A, then the blockchain will be unable to store the change back to state A. \n",
    "- LOGGING_LEVEL: Integer from 0 to 50. Determines the level of logging. The most useful levels are 10 (DEBUG) and 20 (INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4210bdd-5f3c-439d-a32a-e727331dadd9",
   "metadata": {},
   "source": [
    "It would be nice to set these environment variables from within a notebook, so I added functionality to do this using \"magic command\" syntax. Starting a cell with `%ENV` will allow you to set environment variables as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ebda0a-70d5-4dbc-a5c6-6a26f9673d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET ENV BLOCKCHAIN=0\n",
      "SET ENV REDIS=1\n",
      "SET ENV TIMESTAMPING=1\n",
      "SET ENV LOGGING_LEVEL=20"
     ]
    }
   ],
   "source": [
    "%ENV\n",
    "BLOCKCHAIN=0\n",
    "REDIS=1\n",
    "TIMESTAMPING=1\n",
    "LOGGING_LEVEL=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc78c95-d998-459a-aec2-dfe58284ee7b",
   "metadata": {},
   "source": [
    "Other magic commands are supported. For example, to change the fact file when running Prolog, we can use the `%file` command: (note that fact files are stored under the `consulted_files` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b3ec720-aecd-43aa-9d33-aa4cbc51afe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redis storing b3a26cf295a4cd33d6e17b94ce65d18f@swipluser-foo-hash"
     ]
    }
   ],
   "source": [
    "%file: foo.pl\n",
    "\n",
    "man(socrates).\n",
    "mortal(X) :- man(X)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f4907e-1f3d-466b-8b90-089e8f514cd8",
   "metadata": {},
   "source": [
    "We can use `%python` to run python code in a Prolog notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9313c080-1309-42a2-b541-dbcd97341691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x+y=3"
     ]
    }
   ],
   "source": [
    "%python\n",
    "x=1\n",
    "y=2\n",
    "print(f\"{x+y=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb91e815-592d-4c12-b9ed-19a34061272a",
   "metadata": {},
   "source": [
    "And we can consult files from the redis database using `%consult`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd13351-b42f-45d2-8bbe-6414e51017fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3a26cf295a4cd33d6e17b94ce65d18f@swipluser-foo-hash\n",
      "% 1643674741031871443\n",
      "man(socrates).\n",
      "mortal(X) :- man(X).\n",
      "--------------------------------------------------------------------------------\n",
      "Successfully consulted foo.pl\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%consult\n",
    "b3a26cf295a4cd33d6e17b94ce65d18f@swipluser-foo-hash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8f893-bce3-4dba-80c7-f9380bc64a73",
   "metadata": {},
   "source": [
    "Using these extra kernel functions we can easily develop some example scenarios to demonstrate how this technology could be used in a veracity context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2238f6-184f-416f-8b1d-679df8a35950",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Iroha Utilities\n",
    "\n",
    "Before we move on to demonstrations, we need to discuss the Iroha utilities built for this project. These utilities form the backbone of the examples and streamline the process of working with Iroha. As discussed above, the Iroha blockchain is moderately well documented, but creating applications with this documentation takes a long time. The IrohaUtils package (located under `IrohaUtils`) is designed to make interactions with the blockchain infrastructure much easier. Full documentation of this package can be found under the `IrohaUtils/pydocs` directory.\n",
    "\n",
    "When working with file hashes, we will also use IrohaHashCustodian module. This module handles the creation of domains and sending of hashes to the blockchain, as well as checking if hashes are present on the chain. It is important to note that this module relies heavily on querying the blockchain to check for the existence of hashes, which can become very slow for larger chains if the entire chain is queried for each hash. To avoid this, IrohaHashCustodian uses a BlockStorehouse that caches all blocks locally as they are seen, so the query can be run on local blocks before asking the chain for new blocks. This significantly speeds up the query process at the cost of a little space, but is well worth it.\n",
    "\n",
    "Given more time, I would like to expand these modules a bit and make them available using pip install or otherwise. I would also like to add better caching functionality to the BlockStorehouse as currently all blocks are stored forever, which is not ideal for very large chains. Also, the admin user is exposed in IrohaUtils, making this module not suitable for production use, so I would like to implement something more secure. However, for a simple demonstration the modules work fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5d82f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Putting it all together\n",
    "\n",
    "Finally, we have seen enough of the infrastructure and modules that we can get a broad overview of how this project works. Assuming that `BLOCKCHAIN=1`, `TIMESTAMPING=1` and `REDIS=1`, the intended process for interaction is:\n",
    "- At startup of the kernel the user blockchain data (private key) is loaded and an IrohaHashCustodian is created. \n",
    "- A Prolog cell is created and run, defining some facts about a system (the local kernel believes these facts but a different kernel does not)\n",
    "- Upon running the cell, the SWIPL kernel timestamps the file (adding the current time to the start of the file) and hashes the file. A new domain on the blockchain is created by the IrohaHashCustodian, and the resulting file hash is stored on the blockchain.\n",
    "- The kernel then stores the file hash in the redis database, mapping the hash to the file itself.\n",
    "\n",
    "These final three points can be repeated any number of times, creating any number of files and adding these to the factbase. After the local user has finished creating files, we know all of these file hashes are stored on the block chain and the file hashes are mapped (via redis) to the original files. If the local user then runs some arbitrary query on this factbase, they will get some result. Exciting! But so far nothing exceptional has happened.\n",
    "\n",
    "Now consider what happens if a different user (User B) wants to verify the original users (User A) query. This other user must know the entire factbase of User A before running the query, but asking User A directly could result in compromised communication or corruption somewhere along the path. User B could therefore:\n",
    "\n",
    "- Start the kernel, loading User B login data and creating an IrohaHashCustodian\n",
    "- Query the blockchain for all hashes in the domain User A created\n",
    "- With this list of hashes, User B can run the %CONSULT magic cell command\n",
    "- The kernel will now take each hash and feed it through the redis database, converting hashes back to files, and loading these files into the fact base\n",
    "- User B can now run the query with the same factbase as User A, getting the same results\n",
    "\n",
    "Of course there is still some issues with this method. Communication could still be compromised or corrupted between the blockchain or redis database and User B. The redis database could map from the hash to an incorrect file (particularly if User A is malicious in storing the file hash). The process overall is much more complicated. \n",
    "\n",
    "However, the upsides are very important! Because the blockchain is queried rather than an individual user we can be sure that *any* user will get the same query results, while if User A is queried they could change answers based on who is querying. If encryption of files is implemented in the redis database then we can be sure that the correct file is stored in the data base (i.e. the file is encrypted by User A so must be decrypted using their public key, so User B can be sure the file is both stored by User A and has the correct hash). Finally, we should consider involving more than two users. If we had several users, all considered authoritative on some selection of facts, we could suppose that each user may only commit facts that they are authoritative over. Each other user could then collect the committed hashes and apply only those files with facts from authoritative users. This would mean we have a system where some users can set some facts and other users other facts, but *all* users can see *all* facts and agree on them.\n",
    "\n",
    "As an example, in an organic supply chain we could state that a farmer could assert facts about their farming practices, a transporter could assert facts about transportation, a supermarket could assert facts about storage, and a consumer could collect all of these facts to determine the organic status of a product. Because these facts are committed to the blockchain all users can be sure that their factbase comes from authoritative sources, all assertions are public and agreed upon, and all users have the same factbase.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb532b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Demonstrations\n",
    "\n",
    "Now that we have discussed how blockchain technology fits into this project, we should look at some demonstrations.\n",
    "\n",
    "- `prolog-demonstration.ipynb` is a notebook showing how Prolog cells can be run in a notebook, then showing that those Prolog fact files can be stored on the blockchain, and finally how the blockchain can be queried to get file hashes from a domain.\n",
    "- `hash-consult.ipynb` shows how a Prolog cell can be logged on the blockchain then later called from the chain and inserted into the factbase without needing to run the cell locally.\n",
    "- `blockchain-testing.ipynb` shows some simple testing of the blockchain to demonstrate that the chain is secure and reliable, even in the face of malicious users.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWI-Prolog",
   "language": "",
   "name": "swi-kernel"
  },
  "language_info": {
   "mimetype": "text/plain",
   "name": "swipl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
