{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb1ed0a-f108-4da5-b3c9-13f2dd1f4851",
   "metadata": {},
   "source": [
    "# Veracity Project: Distributed Ledgers and Prolog\n",
    "## Hayden McAlister - University of Otago 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d36be8-78bf-4090-a9ac-fa6a551bebc1",
   "metadata": {},
   "source": [
    "### Running this demonstration\n",
    "This demonstration is (currently) hosted on [Catalyst Cloud](https://catalystcloud.nz/). However, the IP address associated with this project is floating and could change regularly. If desired, this could be assigned some fixed domain name so this demonstration could be accessed anywhere, anytime.\n",
    "\n",
    "Otherwise, this demonstration is accessible from GitHub as a docker-compose system. [This repository](TODO) describes how to download, run, and interact with this demonstration locally. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a4185-6f9f-4a1a-b202-8dcd504545ae",
   "metadata": {},
   "source": [
    "## The infrastructure\n",
    "\n",
    "In this research project we investigated how distributed ledger technology could be used in a veracity context to verify claims and reach consensus on the state of a system. Other research was done concurrently into using Prolog to describe the state of a system and look at provenance in an organ donation scenario. I built the infrastructure to integrate this Prolog into a jupyter notebook (for accessibility and easy interaction) and expose the blockchain for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eeec1c-89f1-45e3-98b0-8833655aeb5d",
   "metadata": {},
   "source": [
    "We agreed that for a proof of concept a small scale, locally hosted blockchain would be most suitable. There is no need to put our tests on a \"real\" ledger at this stage, but if this project moves forward in this direction it may be useful to put information on a public ledger so it can be verified.\n",
    "\n",
    "My first task was to find a suitable blockchain technology that could be locally hosted. I found [Hyperledger](https://www.hyperledger.org/) to be very promising, as the opensource projects could be locally hosted and seemed very flexible to cover many situations. I looked in to using Hyperledger [Indy](https://www.hyperledger.org/use/hyperledger-indy), [Aries](https://www.hyperledger.org/use/aries), [Besu](https://www.hyperledger.org/use/besu), and [Ursa](https://www.hyperledger.org/use/ursa) but determined that [Hyperledger Iroha](https://www.hyperledger.org/use/iroha) would be most suitable for my needs. This is mainly due to Iroha having the best documentation of the projects I looked at, and was the easiest to start developing with quickly. However, other projects could absolutely be used and in future local hosting may not even be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb382ee6-8dff-4709-8dd8-562d42894e4f",
   "metadata": {},
   "source": [
    "I spent several weeks setting up infrastructure using Iroha and Docker. I managed to get four Iroha nodes running and comunicating in separate containers, which is significant as four nodes is the minimum neccisary to detect and correct for a single faulty node (crash fault or byzantine fault). While this demonstration does not look any further into faulty nodes, this infrastructure would support probing in this direction.\n",
    "\n",
    "We can see these containers running. If running this demonstration locally, you can run \n",
    "\n",
    "`docker container ls`\n",
    "\n",
    "and spot the containers labeled `iroha1` through `iroha4`. These containers are hosting the blockchain nodes and are constantly communicating to see if new transactions have arrived. These nodes are backed by the containers `some-postgres1` through `some-postgres4`. I am sure with enough convincing the postgres containers could be consolidated into a single container with several logins (one for each Iroha node), however this infrastructure was the easiest to develop quickly. \n",
    "\n",
    "We can also see what the current state of the blockchain is by running the following command. We will discuss this command later on, but for now just know it will query `iroha1` and get all blocks on the chain, storing them in `logs/blocks.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ce9597d-b941-4138-9005-b66854c740bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "%python\n",
    "from IrohaUtils import *\n",
    "log_all_blocks(\"blocks.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b5865-2b92-47b9-bcad-f0cb220df414",
   "metadata": {},
   "source": [
    "We can see in this file that the blocks are represented in JSON format, and are mostly incomprehensible jargon. A lot of this can be understood by trawling through [the documentation](https://iroha.readthedocs.io/en/main/), however this is time consuming and very dense (I said the documentation was the best of the projects above, I did not claim the documentation was clear). For this reason, I have developed some tools we will discuss soon that make developing and interacting with the Iroha network much easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac304221-10b0-42de-bc90-7316f753f7d8",
   "metadata": {},
   "source": [
    "You may also notice other containers running due to this network. There is the `swipl-notebook` container which, unsurprisingly, runs the jupyter notebook server you are interacting with now! There is also a redis container which we will discuss later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3688ff7e-9373-4405-bc53-07c01451bc52",
   "metadata": {},
   "source": [
    "Because the goal of this project was to eventually host some Prolog work, we had to get Prolog running in a jupyter notebook. Thankfully this task was done for us (and can be found [here](https://github.com/veracitylab/jupyter-swi-prolog)), and with some scripting the jupyter notebook can run Prolog code! The kernel essentially runs Prolog line by line through a python interface with SWIPL, then dumps the factbase into a file for consultation later. These files are referenced by Prolog when querying the factbase, so the files store the state of the world. This will be useful later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56200a0-23e1-483c-b18a-fb96c4cff6d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Kernel modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2aeda6-c1d1-4233-be16-94933470d1e1",
   "metadata": {},
   "source": [
    "The kernel, while fantastic, needed extending to work with the blockchain network. I added some extra functionality which made development of Prolog with the blockchain a little easier.\n",
    "\n",
    "First, the kernel checks environment variables to determine state. This means we can easily turn on or off functionality as needed. The supported variables are:\n",
    "\n",
    "- BLOCKCHAIN: 0 or 1. Boolean check to interact with the blockchain or not. If 1 then after executing a Prolog cell the kernel will hash the fact file and store this hash on the blockchain. This provides proof that a cell was run and was added to a fact base.\n",
    "- REDIS: 0 or 1. Boolean check to interact with the redis container or not. If 1 then after execution of a Prolog cell the kernel will map the hash of the fact file with the fact file text itself. This means that if a hash is known (say, if we found it on the blockchain) then we can retrive the file that generated it. Currently, these files are stored unencrypted\n",
    "- TIMESTAMPING: 0 or 1. Boolean check to add a timestamp to the fact files before hashing. If 0, no timestamp is added. This means that if a cell is run multiple times then only the first fact file can be stored. In particular, this means that if a cell undergoes a change from state A to B to A, then the blockchain will be unable to store the change back to state A. \n",
    "- LOGGING_LEVEL: Integer from 0 to 50. Determines the level of logging. The most useful levels are 10 (DEBUG) and 20 (INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4210bdd-5f3c-439d-a32a-e727331dadd9",
   "metadata": {},
   "source": [
    "It would be nice to set these environment variables from within a notebook, so I added functionality to do this using \"magic command\" syntax. Starting a cell with `%ENV` will allow you to set environment variables as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ebda0a-70d5-4dbc-a5c6-6a26f9673d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET ENV BLOCKCHAIN=0\n",
      "SET ENV REDIS=1\n",
      "SET ENV TIMESTAMPING=1\n",
      "SET ENV LOGGING_LEVEL=20"
     ]
    }
   ],
   "source": [
    "%ENV\n",
    "BLOCKCHAIN=0\n",
    "REDIS=1\n",
    "TIMESTAMPING=1\n",
    "LOGGING_LEVEL=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc78c95-d998-459a-aec2-dfe58284ee7b",
   "metadata": {},
   "source": [
    "Other magic commands are supported. For example, to change the fact file when running Prolog, we can use the `%file` command: (note that fact files are stored under the `consulted_files` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b3ec720-aecd-43aa-9d33-aa4cbc51afe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redis storing b3a26cf295a4cd33d6e17b94ce65d18f@swipluser-foo-hash"
     ]
    }
   ],
   "source": [
    "%file: foo.pl\n",
    "\n",
    "man(socrates).\n",
    "mortal(X) :- man(X)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f4907e-1f3d-466b-8b90-089e8f514cd8",
   "metadata": {},
   "source": [
    "We can use `%python` to run python code in a Prolog notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9313c080-1309-42a2-b541-dbcd97341691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x+y=3"
     ]
    }
   ],
   "source": [
    "%python\n",
    "x=1\n",
    "y=2\n",
    "print(f\"{x+y=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb91e815-592d-4c12-b9ed-19a34061272a",
   "metadata": {},
   "source": [
    "And we can consult files from the REDIS database using `%consult`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd13351-b42f-45d2-8bbe-6414e51017fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3a26cf295a4cd33d6e17b94ce65d18f@swipluser-foo-hash\n",
      "% 1643674741031871443\n",
      "man(socrates).\n",
      "mortal(X) :- man(X).\n",
      "--------------------------------------------------------------------------------\n",
      "Successfully consulted foo.pl\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%consult\n",
    "b3a26cf295a4cd33d6e17b94ce65d18f@swipluser-foo-hash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8f893-bce3-4dba-80c7-f9380bc64a73",
   "metadata": {},
   "source": [
    "Using these extra kernel functions we can easily develop some example scenarios to demonstrate how this technology could be used in a veracity context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2238f6-184f-416f-8b1d-679df8a35950",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Iroha Utilities\n",
    "\n",
    "The final part of my project to discuss before we are able to move in to demonstrations is the Iroha utilities I have created. As discussed above, the Iroha network is moderately well documented, and creating applications with this documentation takes a long time. For this reason I have created the IrohaUtils package which provides many functions to quickly interact with the Iroha network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWI-Prolog",
   "language": "",
   "name": "swi-kernel"
  },
  "language_info": {
   "mimetype": "text/plain",
   "name": "swipl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
